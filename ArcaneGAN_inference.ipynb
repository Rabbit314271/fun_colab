{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArcaneGAN inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rabbit314271/fun_colab/blob/main/ArcaneGAN_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzYVMxTPTdmw"
      },
      "source": [
        "An inference notebook for [ArcaneGAN v0.3](https://github.com/Sxela/ArcaneGAN/releases/tag/v0.3).\n",
        "Made by [Alex Spirin](https://twitter.com/devdef)\n",
        "\n",
        "If you like what I'm doing you can tip me [here](https://donationalerts.com/r/derplearning) or follow on [Patreon](https://www.patreon.com/sxela)\n",
        "\n",
        "![visitors](https://visitor-badge.glitch.me/badge?page_id=sxela_arcanegan)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9ikXFtITiuK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "26c13aff-ad7a-4531-ad98-73b09bbb4367"
      },
      "source": [
        "#@title This colab is distributed under the MIT license\n",
        "\"\"\"MIT License\n",
        "\n",
        "Copyright (c) 2021 Alex Spirin\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'MIT License\\n\\nCopyright (c) 2021 Alex Spirin\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXqfcKRpS5Bi",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d9232a-bec2-4533-dc23-cda04ee7015f"
      },
      "source": [
        "#@title Install and download. Run once.\n",
        "#release v0.2\n",
        "!wget https://github.com/Sxela/ArcaneGAN/releases/download/v0.1/ArcaneGANv0.1.jit\n",
        "!wget https://github.com/Sxela/ArcaneGAN/releases/download/v0.2/ArcaneGANv0.2.jit\n",
        "!wget https://github.com/Sxela/ArcaneGAN/releases/download/v0.3/ArcaneGANv0.3.jit\n",
        "!wget https://github.com/Sxela/ArcaneGAN/releases/download/v0.4/ArcaneGANv0.4.jit\n",
        "!pip -qq install facenet_pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-28 12:14:00--  https://github.com/Sxela/ArcaneGAN/releases/download/v0.1/ArcaneGANv0.1.jit\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/382acf3d-4259-4419-8eed-10fed3980c09?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211228T121400Z&X-Amz-Expires=300&X-Amz-Signature=05082e9f875dba5e6f3fb9786a34d67f4243bca7a926181e8c7f16c3133d648f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.1.jit&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-28 12:14:00--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/382acf3d-4259-4419-8eed-10fed3980c09?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211228T121400Z&X-Amz-Expires=300&X-Amz-Signature=05082e9f875dba5e6f3fb9786a34d67f4243bca7a926181e8c7f16c3133d648f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.1.jit&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83394634 (80M) [application/octet-stream]\n",
            "Saving to: ‘ArcaneGANv0.1.jit’\n",
            "\n",
            "ArcaneGANv0.1.jit   100%[===================>]  79.53M  35.9MB/s    in 2.2s    \n",
            "\n",
            "2021-12-28 12:14:02 (35.9 MB/s) - ‘ArcaneGANv0.1.jit’ saved [83394634/83394634]\n",
            "\n",
            "--2021-12-28 12:14:02--  https://github.com/Sxela/ArcaneGAN/releases/download/v0.2/ArcaneGANv0.2.jit\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/52b19f21-13c4-49ea-b920-34d22f01f71b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211228T121402Z&X-Amz-Expires=300&X-Amz-Signature=41204e4a1dc88bd09591f3e63a685d86821e86080b5b5ed2184e3bc865151a37&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.2.jit&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-28 12:14:02--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/52b19f21-13c4-49ea-b920-34d22f01f71b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211228T121402Z&X-Amz-Expires=300&X-Amz-Signature=41204e4a1dc88bd09591f3e63a685d86821e86080b5b5ed2184e3bc865151a37&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.2.jit&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83386102 (80M) [application/octet-stream]\n",
            "Saving to: ‘ArcaneGANv0.2.jit’\n",
            "\n",
            "ArcaneGANv0.2.jit   100%[===================>]  79.52M  28.5MB/s    in 2.8s    \n",
            "\n",
            "2021-12-28 12:14:06 (28.5 MB/s) - ‘ArcaneGANv0.2.jit’ saved [83386102/83386102]\n",
            "\n",
            "--2021-12-28 12:14:06--  https://github.com/Sxela/ArcaneGAN/releases/download/v0.3/ArcaneGANv0.3.jit\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/7751d68c-f131-494d-842c-fd6a94a8c56f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211228T121406Z&X-Amz-Expires=300&X-Amz-Signature=a27daeede519b7446431039767eec2abfa86e7890ffb961a16c6a991834915fc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.3.jit&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-28 12:14:06--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/7751d68c-f131-494d-842c-fd6a94a8c56f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211228T121406Z&X-Amz-Expires=300&X-Amz-Signature=a27daeede519b7446431039767eec2abfa86e7890ffb961a16c6a991834915fc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.3.jit&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83258790 (79M) [application/octet-stream]\n",
            "Saving to: ‘ArcaneGANv0.3.jit’\n",
            "\n",
            "ArcaneGANv0.3.jit   100%[===================>]  79.40M  26.8MB/s    in 3.0s    \n",
            "\n",
            "2021-12-28 12:14:09 (26.8 MB/s) - ‘ArcaneGANv0.3.jit’ saved [83258790/83258790]\n",
            "\n",
            "--2021-12-28 12:14:09--  https://github.com/Sxela/ArcaneGAN/releases/download/v0.4/ArcaneGANv0.4.jit\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/4e22cf6c-d712-46f5-a6ac-fb7c859115f9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211228T121409Z&X-Amz-Expires=300&X-Amz-Signature=11ba75537ccf84ad93de588b831af2b387c8d65744f0cb3e504b19245995cdfd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.4.jit&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-28 12:14:09--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/435295742/4e22cf6c-d712-46f5-a6ac-fb7c859115f9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211228T121409Z&X-Amz-Expires=300&X-Amz-Signature=11ba75537ccf84ad93de588b831af2b387c8d65744f0cb3e504b19245995cdfd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=435295742&response-content-disposition=attachment%3B%20filename%3DArcaneGANv0.4.jit&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62654853 (60M) [application/octet-stream]\n",
            "Saving to: ‘ArcaneGANv0.4.jit’\n",
            "\n",
            "ArcaneGANv0.4.jit   100%[===================>]  59.75M  34.3MB/s    in 1.7s    \n",
            "\n",
            "2021-12-28 12:14:11 (34.3 MB/s) - ‘ArcaneGANv0.4.jit’ saved [62654853/62654853]\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 7.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm7x7XgxUUwv"
      },
      "source": [
        "#@title Define functions\n",
        "#@markdown Select model version and run.\n",
        "from facenet_pytorch import MTCNN\n",
        "from torchvision import transforms\n",
        "import torch, PIL\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "mtcnn = MTCNN(image_size=256, margin=80)\n",
        "\n",
        "# simplest ye olde trustworthy MTCNN for face detection with landmarks\n",
        "def detect(img):\n",
        " \n",
        "        # Detect faces\n",
        "        batch_boxes, batch_probs, batch_points = mtcnn.detect(img, landmarks=True)\n",
        "        # Select faces\n",
        "        if not mtcnn.keep_all:\n",
        "            batch_boxes, batch_probs, batch_points = mtcnn.select_boxes(\n",
        "                batch_boxes, batch_probs, batch_points, img, method=mtcnn.selection_method\n",
        "            )\n",
        " \n",
        "        return batch_boxes, batch_points\n",
        "\n",
        "# my version of isOdd, should make a separate repo for it :D\n",
        "def makeEven(_x):\n",
        "  return _x if (_x % 2 == 0) else _x+1\n",
        "\n",
        "# the actual scaler function\n",
        "def scale(boxes, _img, max_res=1_500_000, target_face=256, fixed_ratio=0, max_upscale=2, VERBOSE=False):\n",
        " \n",
        "    x, y = _img.size\n",
        " \n",
        "    ratio = 2 #initial ratio\n",
        " \n",
        "    #scale to desired face size\n",
        "    if (boxes is not None):\n",
        "      if len(boxes)>0:\n",
        "        ratio = target_face/max(boxes[0][2:]-boxes[0][:2]); \n",
        "        ratio = min(ratio, max_upscale)\n",
        "        if VERBOSE: print('up by', ratio)\n",
        "    global fac\n",
        "    if fac is not None:\n",
        "      ratio=fac\n",
        "    else:\n",
        "      fac=ratio\n",
        "    if fixed_ratio>0:\n",
        "      if VERBOSE: print('fixed ratio')\n",
        "      ratio = fixed_ratio\n",
        " \n",
        "    x*=ratio\n",
        "    y*=ratio\n",
        " \n",
        "    #downscale to fit into max res \n",
        "    res = x*y\n",
        "    if res > max_res:\n",
        "      ratio = pow(res/max_res,1/2); \n",
        "      if VERBOSE: print(ratio)\n",
        "      x=int(x/ratio)\n",
        "      y=int(y/ratio)\n",
        " \n",
        "    #make dimensions even, because usually NNs fail on uneven dimensions due skip connection size mismatch\n",
        "    x = makeEven(int(x))\n",
        "    y = makeEven(int(y))\n",
        "    \n",
        "    size = (x, y)\n",
        "\n",
        "    return _img.resize(size)\n",
        "\n",
        "\"\"\" \n",
        "    A useful scaler algorithm, based on face detection.\n",
        "    Takes PIL.Image, returns a uniformly scaled PIL.Image\n",
        "    boxes: a list of detected bboxes\n",
        "    _img: PIL.Image\n",
        "    max_res: maximum pixel area to fit into. Use to stay below the VRAM limits of your GPU.\n",
        "    target_face: desired face size. Upscale or downscale the whole image to fit the detected face into that dimension.\n",
        "    fixed_ratio: fixed scale. Ignores the face size, but doesn't ignore the max_res limit.\n",
        "    max_upscale: maximum upscale ratio. Prevents from scaling images with tiny faces to a blurry mess.\n",
        "\"\"\"\n",
        "\n",
        "def scale_by_face_size(_img, max_res=1_500_000, target_face=256, fix_ratio=0, max_upscale=2, VERBOSE=False):\n",
        "    boxes = None\n",
        "    boxes, _ = detect(_img)\n",
        "    if VERBOSE: print('boxes',boxes)\n",
        "    global siz\n",
        "    if siz is not None:\n",
        "      boxes=siz\n",
        "    else:\n",
        "      siz=boxes\n",
        "    img_resized = scale(boxes, _img, max_res, target_face, fix_ratio, max_upscale, VERBOSE)\n",
        "    return img_resized\n",
        "\n",
        "\n",
        "size = 256\n",
        "\n",
        "means = [0.485, 0.456, 0.406]\n",
        "stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "t_stds = torch.tensor(stds).cuda().half()[:,None,None]\n",
        "t_means = torch.tensor(means).cuda().half()[:,None,None]\n",
        "\n",
        "def makeEven(_x):\n",
        "  return int(_x) if (_x % 2 == 0) else int(_x+1)\n",
        "\n",
        "img_transforms = transforms.Compose([                        \n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(means,stds)])\n",
        " \n",
        "def tensor2im(var):\n",
        "     return var.mul(t_stds).add(t_means).mul(255.).clamp(0,255).permute(1,2,0)\n",
        "\n",
        "def proc_pil_img(input_image, model):\n",
        "    transformed_image = img_transforms(input_image)[None,...].cuda().half()\n",
        "            \n",
        "    with torch.no_grad():\n",
        "        result_image = model(transformed_image)[0]\n",
        "        output_image = tensor2im(result_image)\n",
        "        output_image = output_image.detach().cpu().numpy().astype('uint8')\n",
        "        output_image = PIL.Image.fromarray(output_image)\n",
        "    return output_image\n",
        "\n",
        "#load model\n",
        "\n",
        "version = '0.4' #@param ['0.1','0.2','0.3','0.4']\n",
        "\n",
        "model_path = f'/content/ArcaneGANv{version}.jit' \n",
        "in_dir = '/content/in'\n",
        "out_dir = f\"/content/{model_path.split('/')[-1][:-4]}_out\"\n",
        "\n",
        "model = torch.jit.load(model_path).eval().cuda().half()\n",
        "\n",
        "#setup colab interface\n",
        "\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output \n",
        "from IPython.display import display\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "def reset(p):\n",
        "  with output_reset:\n",
        "    clear_output()\n",
        "  clear_output()\n",
        "  process()\n",
        " \n",
        "button_reset = widgets.Button(description=\"Upload\")\n",
        "output_reset = widgets.Output()\n",
        "button_reset.on_click(reset)\n",
        "\n",
        "def fit(img,maxsize=512):\n",
        "  maxdim = max(*img.size)\n",
        "  if maxdim>maxsize:\n",
        "    ratio = maxsize/maxdim\n",
        "    x,y = img.size\n",
        "    size = (int(x*ratio),int(y*ratio)) \n",
        "    img = img.resize(size)\n",
        "  return img\n",
        " \n",
        "def show_img(f, size=1024):\n",
        "  display(fit(PIL.Image.open(f),size))\n",
        "\n",
        "def process(upload=True):\n",
        "  os.makedirs(in_dir, exist_ok=True)\n",
        "  %cd {in_dir}/\n",
        "  !rm -rf {out_dir}/*\n",
        "  os.makedirs(out_dir, exist_ok=True)\n",
        "  in_files = sorted(glob(f'{in_dir}/*'))\n",
        "  if (len(in_files)==0) | (upload):\n",
        "    !rm -rf {in_dir}/*\n",
        "    uploaded = files.upload()\n",
        "    if len(uploaded.keys())<=0: \n",
        "      print('\\nNo files were uploaded. Try again..\\n')\n",
        "      return\n",
        "\n",
        "  \n",
        "\n",
        "  print('\\nPress the button and pick some photos to upload\\n')\n",
        "  \n",
        "  in_files = sorted(glob(f'{in_dir}/*'))\n",
        "  for img in tqdm(in_files):\n",
        "    out = f\"{out_dir}/{img.split('/')[-1].split('.')[0]}.jpg\"\n",
        "    im = PIL.Image.open(img)\n",
        "    im = scale_by_face_size(im, target_face=300, max_res=1_500_000, max_upscale=2)\n",
        "    res = proc_pil_img(im, model)\n",
        "    res.save(out)\n",
        "\n",
        "  out_zip = f\"{out_dir}.zip\"\n",
        "  !zip {out_zip} {out_dir}/*\n",
        "    \n",
        "  processed = sorted(glob(f'{out_dir}/*'))[:3]\n",
        "  for f in processed: \n",
        "    show_img(f, 256)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "def save_img(video_path):\n",
        "    videos = os.listdir(video_path)\n",
        "    for video_name in videos:\n",
        "        if video_name[-3:]=='jit':\n",
        "          continue\n",
        "        file_name = video_name.split('.')[0]\n",
        "        folder_name = video_path + file_name\n",
        "        os.makedirs(folder_name,exist_ok=True)\n",
        "        vc = cv2.VideoCapture(video_path+video_name) #读入视频文件\n",
        "        c=0\n",
        "        rval=vc.isOpened()\n",
        "\n",
        "        while rval:   #循环读取视频帧\n",
        "            c = c + 1\n",
        "            rval, frame = vc.read()\n",
        "            pic_path = folder_name+'/'\n",
        "            if rval:\n",
        "                img = Image.fromarray(np.rot90((cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)),k=-1))\n",
        "                #img = Image.fromarray(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))\n",
        "                img = scale_by_face_size(img, target_face=300, max_res=1_500_000, max_upscale=2)\n",
        "                res = proc_pil_img(img, model)\n",
        "                res.save(pic_path +  str(c) + '.jpg') #存储为图像,保存名为 文件夹名_数字（第几个文件）.jpg\n",
        "                cv2.waitKey(1)\n",
        "                if c%100==0:\n",
        "                  print(c)\n",
        "                  print(res.size)\n",
        "                \n",
        "            else:\n",
        "                break\n",
        "        vc.release()\n",
        "        print('save_success')\n",
        "        print(folder_name)\n",
        "\n",
        "siz=None\n",
        "fac= None\n",
        "save_img('/content/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "petPyDys5bAp",
        "outputId": "a791be79-d7e3-4395-e428-5c0f5478f023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save_success\n",
            "/content/\n",
            "100\n",
            "(214, 380)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8971ce0a6683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0msiz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mfac\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0msave_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-8971ce0a6683>\u001b[0m in \u001b[0;36msave_img\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;31m#img = Image.fromarray(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_by_face_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_face\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1_500_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_upscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc_pil_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic_path\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#存储为图像,保存名为 文件夹名_数字（第几个文件）.jpg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ae4ae4dab45e>\u001b[0m in \u001b[0;36mscale_by_face_size\u001b[0;34m(_img, max_res, target_face, fix_ratio, max_upscale, VERBOSE)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscale_by_face_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1_500_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_face\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_upscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVERBOSE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mVERBOSE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'boxes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0msiz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ae4ae4dab45e>\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Detect faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mbatch_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Select faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmtcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/mtcnn.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, landmarks)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             )\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/utils/detect_face.py\u001b[0m in \u001b[0;36mdetect_face\u001b[0;34m(imgs, minsize, pnet, rnet, onet, threshold, factor, device)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscales\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mim_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mim_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mim_data\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.0078125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/facenet_pytorch/models/utils/detect_face.py\u001b[0m in \u001b[0;36mimresample\u001b[0;34m(img, sz)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m     \u001b[0mim_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"area\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[1;32m   3719\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"area\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3720\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3721\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3722\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"area\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3723\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36madaptive_avg_pool2d\u001b[0;34m(input, output_size)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0m_output_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_with_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_output_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "path = '/content/IMG_7526'+'/'\n",
        "filelist_len = len(os.listdir(path))\n",
        "\n",
        "fps = 30 \n",
        "size = (214, 380) #需要转为视频的图片的尺寸\n",
        "#可以使用cv2.resize()进行修改\n",
        "video_name=path.split('/')[-2]\n",
        "\n",
        "video = cv2.VideoWriter(\"{}.avi\".format(video_name), cv2.VideoWriter_fourcc('I', '4', '2', '0'), fps, size)\n",
        "#视频保存在当前目录下\n",
        "\n",
        "for i in np.arange(filelist_len):\n",
        "        item = path + str(i+1)+'.jpg'\n",
        "        print(item)\n",
        "        img = cv2.imread(item)\n",
        "        print(img.shape)\n",
        "        video.write(img)\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJHu1_1r6uNY",
        "outputId": "6a92b451-b4db-4f4e-f9f9-8674b1c41b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IMG_7526/1.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/2.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/3.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/4.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/5.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/6.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/7.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/8.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/9.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/10.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/11.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/12.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/13.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/14.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/15.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/16.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/17.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/18.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/19.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/20.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/21.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/22.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/23.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/24.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/25.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/26.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/27.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/28.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/29.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/30.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/31.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/32.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/33.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/34.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/35.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/36.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/37.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/38.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/39.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/40.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/41.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/42.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/43.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/44.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/45.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/46.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/47.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/48.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/49.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/50.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/51.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/52.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/53.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/54.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/55.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/56.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/57.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/58.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/59.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/60.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/61.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/62.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/63.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/64.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/65.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/66.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/67.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/68.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/69.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/70.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/71.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/72.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/73.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/74.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/75.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/76.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/77.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/78.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/79.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/80.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/81.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/82.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/83.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/84.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/85.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/86.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/87.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/88.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/89.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/90.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/91.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/92.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/93.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/94.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/95.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/96.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/97.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/98.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/99.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/100.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/101.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/102.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/103.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/104.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/105.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/106.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/107.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/108.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/109.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/110.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/111.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/112.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/113.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/114.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/115.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/116.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/117.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/118.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/119.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/120.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/121.jpg\n",
            "(380, 214, 3)\n",
            "/content/IMG_7526/122.jpg\n",
            "(380, 214, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/IMG_7526.avi') #参数：文件名"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "z0jXPYMO6ySE",
        "outputId": "3afa2d7e-45d9-4046-ce15-476b3ac757b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cb430898-2dd1-42de-b900-95103ee1af06\", \"IMG_7526.avi\", 14890174)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}